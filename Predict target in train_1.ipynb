{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting target in train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notebook automatically generated from your model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model XGBoost, trained on 2019-03-19 15:22:58."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generated on 2019-03-19 15:37:00.004461"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "prediction\n",
    "This notebook will reproduce the steps for a BINARY_CLASSIFICATION on  train.\n",
    "The main objective is to predict the variable target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Warning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of this notebook is to provide an easily readable and explainable code that reproduces the main steps\n",
    "of training the model. It is not complete: some of the preprocessing done by the DSS visual machine learning is not\n",
    "replicated in this notebook. This notebook will not give the same results and model performance as the DSS visual machine\n",
    "learning model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start with importing the required libs :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn as sk\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And tune pandas display options:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing base data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step is to get our machine learning dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>var_0</th>\n",
       "      <th>var_1</th>\n",
       "      <th>var_2</th>\n",
       "      <th>var_3</th>\n",
       "      <th>var_4</th>\n",
       "      <th>var_5</th>\n",
       "      <th>var_6</th>\n",
       "      <th>var_7</th>\n",
       "      <th>var_8</th>\n",
       "      <th>...</th>\n",
       "      <th>var_190</th>\n",
       "      <th>var_191</th>\n",
       "      <th>var_192</th>\n",
       "      <th>var_193</th>\n",
       "      <th>var_194</th>\n",
       "      <th>var_195</th>\n",
       "      <th>var_196</th>\n",
       "      <th>var_197</th>\n",
       "      <th>var_198</th>\n",
       "      <th>var_199</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.100490</td>\n",
       "      <td>10.679914</td>\n",
       "      <td>-1.627622</td>\n",
       "      <td>10.715192</td>\n",
       "      <td>6.796529</td>\n",
       "      <td>11.078333</td>\n",
       "      <td>-5.065317</td>\n",
       "      <td>5.408949</td>\n",
       "      <td>16.545850</td>\n",
       "      <td>0.284162</td>\n",
       "      <td>...</td>\n",
       "      <td>3.234440</td>\n",
       "      <td>7.438408</td>\n",
       "      <td>1.927839</td>\n",
       "      <td>3.331774</td>\n",
       "      <td>17.993784</td>\n",
       "      <td>-0.142088</td>\n",
       "      <td>2.303335</td>\n",
       "      <td>8.908158</td>\n",
       "      <td>15.870720</td>\n",
       "      <td>-3.326537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.300653</td>\n",
       "      <td>3.040051</td>\n",
       "      <td>4.050044</td>\n",
       "      <td>2.640894</td>\n",
       "      <td>2.043319</td>\n",
       "      <td>1.623150</td>\n",
       "      <td>7.863267</td>\n",
       "      <td>0.866607</td>\n",
       "      <td>3.418076</td>\n",
       "      <td>3.332634</td>\n",
       "      <td>...</td>\n",
       "      <td>4.559922</td>\n",
       "      <td>3.023272</td>\n",
       "      <td>1.478423</td>\n",
       "      <td>3.992030</td>\n",
       "      <td>3.135162</td>\n",
       "      <td>1.429372</td>\n",
       "      <td>5.454369</td>\n",
       "      <td>0.921625</td>\n",
       "      <td>3.010945</td>\n",
       "      <td>10.438015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.408400</td>\n",
       "      <td>-15.043400</td>\n",
       "      <td>2.117100</td>\n",
       "      <td>-0.040200</td>\n",
       "      <td>5.074800</td>\n",
       "      <td>-32.562600</td>\n",
       "      <td>2.347300</td>\n",
       "      <td>5.349700</td>\n",
       "      <td>-10.505500</td>\n",
       "      <td>...</td>\n",
       "      <td>-14.093300</td>\n",
       "      <td>-2.691700</td>\n",
       "      <td>-3.814500</td>\n",
       "      <td>-11.783400</td>\n",
       "      <td>8.694400</td>\n",
       "      <td>-5.261000</td>\n",
       "      <td>-14.209600</td>\n",
       "      <td>5.960600</td>\n",
       "      <td>6.299300</td>\n",
       "      <td>-38.852800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.453850</td>\n",
       "      <td>-4.740025</td>\n",
       "      <td>8.722475</td>\n",
       "      <td>5.254075</td>\n",
       "      <td>9.883175</td>\n",
       "      <td>-11.200350</td>\n",
       "      <td>4.767700</td>\n",
       "      <td>13.943800</td>\n",
       "      <td>-2.317800</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.058825</td>\n",
       "      <td>5.157400</td>\n",
       "      <td>0.889775</td>\n",
       "      <td>0.584600</td>\n",
       "      <td>15.629800</td>\n",
       "      <td>-1.170700</td>\n",
       "      <td>-1.946925</td>\n",
       "      <td>8.252800</td>\n",
       "      <td>13.829700</td>\n",
       "      <td>-11.208475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.524750</td>\n",
       "      <td>-1.608050</td>\n",
       "      <td>10.580000</td>\n",
       "      <td>6.825000</td>\n",
       "      <td>11.108250</td>\n",
       "      <td>-4.833150</td>\n",
       "      <td>5.385100</td>\n",
       "      <td>16.456800</td>\n",
       "      <td>0.393700</td>\n",
       "      <td>...</td>\n",
       "      <td>3.203600</td>\n",
       "      <td>7.347750</td>\n",
       "      <td>1.901300</td>\n",
       "      <td>3.396350</td>\n",
       "      <td>17.957950</td>\n",
       "      <td>-0.172700</td>\n",
       "      <td>2.408900</td>\n",
       "      <td>8.888200</td>\n",
       "      <td>15.934050</td>\n",
       "      <td>-2.819550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.758200</td>\n",
       "      <td>1.358625</td>\n",
       "      <td>12.516700</td>\n",
       "      <td>8.324100</td>\n",
       "      <td>12.261125</td>\n",
       "      <td>0.924800</td>\n",
       "      <td>6.003000</td>\n",
       "      <td>19.102900</td>\n",
       "      <td>2.937900</td>\n",
       "      <td>...</td>\n",
       "      <td>6.406200</td>\n",
       "      <td>9.512525</td>\n",
       "      <td>2.949500</td>\n",
       "      <td>6.205800</td>\n",
       "      <td>20.396525</td>\n",
       "      <td>0.829600</td>\n",
       "      <td>6.556725</td>\n",
       "      <td>9.593300</td>\n",
       "      <td>18.064725</td>\n",
       "      <td>4.836800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>20.315000</td>\n",
       "      <td>10.376800</td>\n",
       "      <td>19.353000</td>\n",
       "      <td>13.188300</td>\n",
       "      <td>16.671400</td>\n",
       "      <td>17.251600</td>\n",
       "      <td>8.447700</td>\n",
       "      <td>27.691800</td>\n",
       "      <td>10.151300</td>\n",
       "      <td>...</td>\n",
       "      <td>18.440900</td>\n",
       "      <td>16.716500</td>\n",
       "      <td>8.402400</td>\n",
       "      <td>18.281800</td>\n",
       "      <td>27.928800</td>\n",
       "      <td>4.272900</td>\n",
       "      <td>18.321500</td>\n",
       "      <td>12.000400</td>\n",
       "      <td>26.079100</td>\n",
       "      <td>28.500700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 201 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              target          var_0          var_1          var_2  \\\n",
       "count  200000.000000  200000.000000  200000.000000  200000.000000   \n",
       "mean        0.100490      10.679914      -1.627622      10.715192   \n",
       "std         0.300653       3.040051       4.050044       2.640894   \n",
       "min         0.000000       0.408400     -15.043400       2.117100   \n",
       "25%         0.000000       8.453850      -4.740025       8.722475   \n",
       "50%         0.000000      10.524750      -1.608050      10.580000   \n",
       "75%         0.000000      12.758200       1.358625      12.516700   \n",
       "max         1.000000      20.315000      10.376800      19.353000   \n",
       "\n",
       "               var_3          var_4          var_5          var_6  \\\n",
       "count  200000.000000  200000.000000  200000.000000  200000.000000   \n",
       "mean        6.796529      11.078333      -5.065317       5.408949   \n",
       "std         2.043319       1.623150       7.863267       0.866607   \n",
       "min        -0.040200       5.074800     -32.562600       2.347300   \n",
       "25%         5.254075       9.883175     -11.200350       4.767700   \n",
       "50%         6.825000      11.108250      -4.833150       5.385100   \n",
       "75%         8.324100      12.261125       0.924800       6.003000   \n",
       "max        13.188300      16.671400      17.251600       8.447700   \n",
       "\n",
       "               var_7          var_8      ...              var_190  \\\n",
       "count  200000.000000  200000.000000      ...        200000.000000   \n",
       "mean       16.545850       0.284162      ...             3.234440   \n",
       "std         3.418076       3.332634      ...             4.559922   \n",
       "min         5.349700     -10.505500      ...           -14.093300   \n",
       "25%        13.943800      -2.317800      ...            -0.058825   \n",
       "50%        16.456800       0.393700      ...             3.203600   \n",
       "75%        19.102900       2.937900      ...             6.406200   \n",
       "max        27.691800      10.151300      ...            18.440900   \n",
       "\n",
       "             var_191        var_192        var_193        var_194  \\\n",
       "count  200000.000000  200000.000000  200000.000000  200000.000000   \n",
       "mean        7.438408       1.927839       3.331774      17.993784   \n",
       "std         3.023272       1.478423       3.992030       3.135162   \n",
       "min        -2.691700      -3.814500     -11.783400       8.694400   \n",
       "25%         5.157400       0.889775       0.584600      15.629800   \n",
       "50%         7.347750       1.901300       3.396350      17.957950   \n",
       "75%         9.512525       2.949500       6.205800      20.396525   \n",
       "max        16.716500       8.402400      18.281800      27.928800   \n",
       "\n",
       "             var_195        var_196        var_197        var_198  \\\n",
       "count  200000.000000  200000.000000  200000.000000  200000.000000   \n",
       "mean       -0.142088       2.303335       8.908158      15.870720   \n",
       "std         1.429372       5.454369       0.921625       3.010945   \n",
       "min        -5.261000     -14.209600       5.960600       6.299300   \n",
       "25%        -1.170700      -1.946925       8.252800      13.829700   \n",
       "50%        -0.172700       2.408900       8.888200      15.934050   \n",
       "75%         0.829600       6.556725       9.593300      18.064725   \n",
       "max         4.272900      18.321500      12.000400      26.079100   \n",
       "\n",
       "             var_199  \n",
       "count  200000.000000  \n",
       "mean       -3.326537  \n",
       "std        10.438015  \n",
       "min       -38.852800  \n",
       "25%       -11.208475  \n",
       "50%        -2.819550  \n",
       "75%         4.836800  \n",
       "max        28.500700  \n",
       "\n",
       "[8 rows x 201 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We apply the preparation that you defined. You should not modify this.\n",
    "\n",
    "train = pd.read_csv(\"train.csv\")\n",
    "#test = pd.read_csv(\"test.csv\")\n",
    "\n",
    "train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import StratifiedKFold, KFold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initial data management"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The preprocessing aims at making the dataset compatible with modeling.\n",
    "At the end of this step, we will have a matrix of float numbers, with no missing values.\n",
    "We'll use the features and the preprocessing steps defined in Models.\n",
    "\n",
    "Let's only keep selected features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first coerce categorical columns into unicode, numerical features into floats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment(x,y,t=2):\n",
    "    xs,xn = [],[]\n",
    "    for i in range(t):\n",
    "        mask = y>0\n",
    "        x1 = x[mask].copy()\n",
    "        ids = np.arange(x1.shape[0])\n",
    "        for c in range(x1.shape[1]):\n",
    "            np.random.shuffle(ids)\n",
    "            x1[:,c] = x1[ids][:,c]\n",
    "        xs.append(x1)\n",
    "\n",
    "    for i in range(t//2):\n",
    "        mask = y==0\n",
    "        x1 = x[mask].copy()\n",
    "        ids = np.arange(x1.shape[0])\n",
    "        for c in range(x1.shape[1]):\n",
    "            np.random.shuffle(ids)\n",
    "            x1[:,c] = x1[ids][:,c]\n",
    "        xn.append(x1)\n",
    "\n",
    "    xs = np.vstack(xs)\n",
    "    xn = np.vstack(xn)\n",
    "    ys = np.ones(xs.shape[0])\n",
    "    yn = np.zeros(xn.shape[0])\n",
    "    x = np.vstack([x,xs,xn])\n",
    "    y = np.concatenate([y,ys,yn])\n",
    "    return x,y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are now going to handle the target variable and store it in a new variable:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cross-validation strategy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a simple cross-validation strategy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Features preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now handle the categorical features (still using the settings defined in Models):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's rescale numerical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rescaled var_48\n",
      "Rescaled var_49\n",
      "Rescaled var_44\n",
      "Rescaled var_45\n",
      "Rescaled var_46\n",
      "Rescaled var_47\n",
      "Rescaled var_40\n",
      "Rescaled var_41\n",
      "Rescaled var_42\n",
      "Rescaled var_43\n",
      "Rescaled var_188\n",
      "Rescaled var_189\n",
      "Rescaled var_184\n",
      "Rescaled var_185\n",
      "Rescaled var_186\n",
      "Rescaled var_187\n",
      "Rescaled var_180\n",
      "Rescaled var_181\n",
      "Rescaled var_182\n",
      "Rescaled var_183\n",
      "Rescaled var_104\n",
      "Rescaled var_105\n",
      "Rescaled var_106\n",
      "Rescaled var_107\n",
      "Rescaled var_100\n",
      "Rescaled var_101\n",
      "Rescaled var_102\n",
      "Rescaled var_103\n",
      "Rescaled var_7\n",
      "Rescaled var_6\n",
      "Rescaled var_5\n",
      "Rescaled var_4\n",
      "Rescaled var_108\n",
      "Rescaled var_109\n",
      "Rescaled var_1\n",
      "Rescaled var_0\n",
      "Rescaled var_59\n",
      "Rescaled var_58\n",
      "Rescaled var_53\n",
      "Rescaled var_52\n",
      "Rescaled var_51\n",
      "Rescaled var_50\n",
      "Rescaled var_57\n",
      "Rescaled var_56\n",
      "Rescaled var_55\n",
      "Rescaled var_54\n",
      "Rescaled var_173\n",
      "Rescaled var_172\n",
      "Rescaled var_131\n",
      "Rescaled var_130\n",
      "Rescaled var_133\n",
      "Rescaled var_132\n",
      "Rescaled var_135\n",
      "Rescaled var_134\n",
      "Rescaled var_137\n",
      "Rescaled var_136\n",
      "Rescaled var_139\n",
      "Rescaled var_138\n",
      "Rescaled var_3\n",
      "Rescaled var_179\n",
      "Rescaled var_178\n",
      "Rescaled var_28\n",
      "Rescaled var_29\n",
      "Rescaled var_26\n",
      "Rescaled var_27\n",
      "Rescaled var_24\n",
      "Rescaled var_25\n",
      "Rescaled var_22\n",
      "Rescaled var_23\n",
      "Rescaled var_20\n",
      "Rescaled var_21\n",
      "Rescaled var_128\n",
      "Rescaled var_129\n",
      "Rescaled var_126\n",
      "Rescaled var_127\n",
      "Rescaled var_124\n",
      "Rescaled var_125\n",
      "Rescaled var_122\n",
      "Rescaled var_123\n",
      "Rescaled var_120\n",
      "Rescaled var_121\n",
      "Rescaled var_39\n",
      "Rescaled var_38\n",
      "Rescaled var_35\n",
      "Rescaled var_34\n",
      "Rescaled var_37\n",
      "Rescaled var_36\n",
      "Rescaled var_31\n",
      "Rescaled var_30\n",
      "Rescaled var_33\n",
      "Rescaled var_32\n",
      "Rescaled var_159\n",
      "Rescaled var_158\n",
      "Rescaled var_153\n",
      "Rescaled var_152\n",
      "Rescaled var_151\n",
      "Rescaled var_150\n",
      "Rescaled var_157\n",
      "Rescaled var_156\n",
      "Rescaled var_155\n",
      "Rescaled var_154\n",
      "Rescaled var_80\n",
      "Rescaled var_81\n",
      "Rescaled var_82\n",
      "Rescaled var_83\n",
      "Rescaled var_84\n",
      "Rescaled var_85\n",
      "Rescaled var_86\n",
      "Rescaled var_87\n",
      "Rescaled var_88\n",
      "Rescaled var_89\n",
      "Rescaled var_148\n",
      "Rescaled var_149\n",
      "Rescaled var_140\n",
      "Rescaled var_141\n",
      "Rescaled var_142\n",
      "Rescaled var_143\n",
      "Rescaled var_144\n",
      "Rescaled var_145\n",
      "Rescaled var_146\n",
      "Rescaled var_147\n",
      "Rescaled var_17\n",
      "Rescaled var_16\n",
      "Rescaled var_15\n",
      "Rescaled var_14\n",
      "Rescaled var_13\n",
      "Rescaled var_12\n",
      "Rescaled var_11\n",
      "Rescaled var_10\n",
      "Rescaled var_8\n",
      "Rescaled var_19\n",
      "Rescaled var_18\n",
      "Rescaled var_175\n",
      "Rescaled var_174\n",
      "Rescaled var_177\n",
      "Rescaled var_176\n",
      "Rescaled var_171\n",
      "Rescaled var_170\n",
      "Rescaled var_99\n",
      "Rescaled var_98\n",
      "Rescaled var_97\n",
      "Rescaled var_96\n",
      "Rescaled var_95\n",
      "Rescaled var_94\n",
      "Rescaled var_93\n",
      "Rescaled var_92\n",
      "Rescaled var_91\n",
      "Rescaled var_90\n",
      "Rescaled var_62\n",
      "Rescaled var_63\n",
      "Rescaled var_60\n",
      "Rescaled var_61\n",
      "Rescaled var_66\n",
      "Rescaled var_67\n",
      "Rescaled var_64\n",
      "Rescaled var_65\n",
      "Rescaled var_68\n",
      "Rescaled var_69\n",
      "Rescaled var_2\n",
      "Rescaled var_162\n",
      "Rescaled var_163\n",
      "Rescaled var_160\n",
      "Rescaled var_161\n",
      "Rescaled var_166\n",
      "Rescaled var_167\n",
      "Rescaled var_164\n",
      "Rescaled var_165\n",
      "Rescaled var_168\n",
      "Rescaled var_169\n",
      "Rescaled var_71\n",
      "Rescaled var_70\n",
      "Rescaled var_73\n",
      "Rescaled var_72\n",
      "Rescaled var_75\n",
      "Rescaled var_74\n",
      "Rescaled var_77\n",
      "Rescaled var_76\n",
      "Rescaled var_79\n",
      "Rescaled var_78\n",
      "Rescaled var_9\n",
      "Rescaled var_199\n",
      "Rescaled var_198\n",
      "Rescaled var_197\n",
      "Rescaled var_196\n",
      "Rescaled var_195\n",
      "Rescaled var_194\n",
      "Rescaled var_193\n",
      "Rescaled var_192\n",
      "Rescaled var_191\n",
      "Rescaled var_190\n",
      "Rescaled var_117\n",
      "Rescaled var_116\n",
      "Rescaled var_115\n",
      "Rescaled var_114\n",
      "Rescaled var_113\n",
      "Rescaled var_112\n",
      "Rescaled var_111\n",
      "Rescaled var_110\n",
      "Rescaled var_119\n",
      "Rescaled var_118\n"
     ]
    }
   ],
   "source": [
    "rescale_features = {u'var_48': u'AVGSTD', u'var_49': u'AVGSTD', u'var_44': u'AVGSTD', u'var_45': u'AVGSTD', u'var_46': u'AVGSTD', u'var_47': u'AVGSTD', u'var_40': u'AVGSTD', u'var_41': u'AVGSTD', u'var_42': u'AVGSTD', u'var_43': u'AVGSTD', u'var_188': u'AVGSTD', u'var_189': u'AVGSTD', u'var_184': u'AVGSTD', u'var_185': u'AVGSTD', u'var_186': u'AVGSTD', u'var_187': u'AVGSTD', u'var_180': u'AVGSTD', u'var_181': u'AVGSTD', u'var_182': u'AVGSTD', u'var_183': u'AVGSTD', u'var_104': u'AVGSTD', u'var_105': u'AVGSTD', u'var_106': u'AVGSTD', u'var_107': u'AVGSTD', u'var_100': u'AVGSTD', u'var_101': u'AVGSTD', u'var_102': u'AVGSTD', u'var_103': u'AVGSTD', u'var_7': u'AVGSTD', u'var_6': u'AVGSTD', u'var_5': u'AVGSTD', u'var_4': u'AVGSTD', u'var_108': u'AVGSTD', u'var_109': u'AVGSTD', u'var_1': u'AVGSTD', u'var_0': u'AVGSTD', u'var_59': u'AVGSTD', u'var_58': u'AVGSTD', u'var_53': u'AVGSTD', u'var_52': u'AVGSTD', u'var_51': u'AVGSTD', u'var_50': u'AVGSTD', u'var_57': u'AVGSTD', u'var_56': u'AVGSTD', u'var_55': u'AVGSTD', u'var_54': u'AVGSTD', u'var_173': u'AVGSTD', u'var_172': u'AVGSTD', u'var_131': u'AVGSTD', u'var_130': u'AVGSTD', u'var_133': u'AVGSTD', u'var_132': u'AVGSTD', u'var_135': u'AVGSTD', u'var_134': u'AVGSTD', u'var_137': u'AVGSTD', u'var_136': u'AVGSTD', u'var_139': u'AVGSTD', u'var_138': u'AVGSTD', u'var_3': u'AVGSTD', u'var_179': u'AVGSTD', u'var_178': u'AVGSTD', u'var_28': u'AVGSTD', u'var_29': u'AVGSTD', u'var_26': u'AVGSTD', u'var_27': u'AVGSTD', u'var_24': u'AVGSTD', u'var_25': u'AVGSTD', u'var_22': u'AVGSTD', u'var_23': u'AVGSTD', u'var_20': u'AVGSTD', u'var_21': u'AVGSTD', u'var_128': u'AVGSTD', u'var_129': u'AVGSTD', u'var_126': u'AVGSTD', u'var_127': u'AVGSTD', u'var_124': u'AVGSTD', u'var_125': u'AVGSTD', u'var_122': u'AVGSTD', u'var_123': u'AVGSTD', u'var_120': u'AVGSTD', u'var_121': u'AVGSTD', u'var_39': u'AVGSTD', u'var_38': u'AVGSTD', u'var_35': u'AVGSTD', u'var_34': u'AVGSTD', u'var_37': u'AVGSTD', u'var_36': u'AVGSTD', u'var_31': u'AVGSTD', u'var_30': u'AVGSTD', u'var_33': u'AVGSTD', u'var_32': u'AVGSTD', u'var_159': u'AVGSTD', u'var_158': u'AVGSTD', u'var_153': u'AVGSTD', u'var_152': u'AVGSTD', u'var_151': u'AVGSTD', u'var_150': u'AVGSTD', u'var_157': u'AVGSTD', u'var_156': u'AVGSTD', u'var_155': u'AVGSTD', u'var_154': u'AVGSTD', u'var_80': u'AVGSTD', u'var_81': u'AVGSTD', u'var_82': u'AVGSTD', u'var_83': u'AVGSTD', u'var_84': u'AVGSTD', u'var_85': u'AVGSTD', u'var_86': u'AVGSTD', u'var_87': u'AVGSTD', u'var_88': u'AVGSTD', u'var_89': u'AVGSTD', u'var_148': u'AVGSTD', u'var_149': u'AVGSTD', u'var_140': u'AVGSTD', u'var_141': u'AVGSTD', u'var_142': u'AVGSTD', u'var_143': u'AVGSTD', u'var_144': u'AVGSTD', u'var_145': u'AVGSTD', u'var_146': u'AVGSTD', u'var_147': u'AVGSTD', u'var_17': u'AVGSTD', u'var_16': u'AVGSTD', u'var_15': u'AVGSTD', u'var_14': u'AVGSTD', u'var_13': u'AVGSTD', u'var_12': u'AVGSTD', u'var_11': u'AVGSTD', u'var_10': u'AVGSTD', u'var_8': u'AVGSTD', u'var_19': u'AVGSTD', u'var_18': u'AVGSTD', u'var_175': u'AVGSTD', u'var_174': u'AVGSTD', u'var_177': u'AVGSTD', u'var_176': u'AVGSTD', u'var_171': u'AVGSTD', u'var_170': u'AVGSTD', u'var_99': u'AVGSTD', u'var_98': u'AVGSTD', u'var_97': u'AVGSTD', u'var_96': u'AVGSTD', u'var_95': u'AVGSTD', u'var_94': u'AVGSTD', u'var_93': u'AVGSTD', u'var_92': u'AVGSTD', u'var_91': u'AVGSTD', u'var_90': u'AVGSTD', u'var_62': u'AVGSTD', u'var_63': u'AVGSTD', u'var_60': u'AVGSTD', u'var_61': u'AVGSTD', u'var_66': u'AVGSTD', u'var_67': u'AVGSTD', u'var_64': u'AVGSTD', u'var_65': u'AVGSTD', u'var_68': u'AVGSTD', u'var_69': u'AVGSTD', u'var_2': u'AVGSTD', u'var_162': u'AVGSTD', u'var_163': u'AVGSTD', u'var_160': u'AVGSTD', u'var_161': u'AVGSTD', u'var_166': u'AVGSTD', u'var_167': u'AVGSTD', u'var_164': u'AVGSTD', u'var_165': u'AVGSTD', u'var_168': u'AVGSTD', u'var_169': u'AVGSTD', u'var_71': u'AVGSTD', u'var_70': u'AVGSTD', u'var_73': u'AVGSTD', u'var_72': u'AVGSTD', u'var_75': u'AVGSTD', u'var_74': u'AVGSTD', u'var_77': u'AVGSTD', u'var_76': u'AVGSTD', u'var_79': u'AVGSTD', u'var_78': u'AVGSTD', u'var_9': u'AVGSTD', u'var_199': u'AVGSTD', u'var_198': u'AVGSTD', u'var_197': u'AVGSTD', u'var_196': u'AVGSTD', u'var_195': u'AVGSTD', u'var_194': u'AVGSTD', u'var_193': u'AVGSTD', u'var_192': u'AVGSTD', u'var_191': u'AVGSTD', u'var_190': u'AVGSTD', u'var_117': u'AVGSTD', u'var_116': u'AVGSTD', u'var_115': u'AVGSTD', u'var_114': u'AVGSTD', u'var_113': u'AVGSTD', u'var_112': u'AVGSTD', u'var_111': u'AVGSTD', u'var_110': u'AVGSTD', u'var_119': u'AVGSTD', u'var_118': u'AVGSTD'}\n",
    "for (feature_name, rescale_method) in rescale_features.items():\n",
    "    if rescale_method == 'MINMAX':\n",
    "        _min = train[feature_name].min()\n",
    "        _max = train[feature_name].max()\n",
    "        scale = _max - _min\n",
    "        shift = _min\n",
    "    else:\n",
    "        shift = train[feature_name].mean()\n",
    "        scale = train[feature_name].std()\n",
    "    if scale == 0.:\n",
    "        del train[feature_name]\n",
    "        del test[feature_name]\n",
    "        print ('Feature %s was dropped because it has no variance' % feature_name)\n",
    "    else:\n",
    "        print ('Rescaled %s' % feature_name)\n",
    "        train[feature_name] = (train[feature_name] - shift).astype(np.float64) / scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID_code</th>\n",
       "      <th>target</th>\n",
       "      <th>var_0</th>\n",
       "      <th>var_1</th>\n",
       "      <th>var_2</th>\n",
       "      <th>var_3</th>\n",
       "      <th>var_4</th>\n",
       "      <th>var_5</th>\n",
       "      <th>var_6</th>\n",
       "      <th>var_7</th>\n",
       "      <th>...</th>\n",
       "      <th>var_190</th>\n",
       "      <th>var_191</th>\n",
       "      <th>var_192</th>\n",
       "      <th>var_193</th>\n",
       "      <th>var_194</th>\n",
       "      <th>var_195</th>\n",
       "      <th>var_196</th>\n",
       "      <th>var_197</th>\n",
       "      <th>var_198</th>\n",
       "      <th>var_199</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train_0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.577100</td>\n",
       "      <td>-1.273734</td>\n",
       "      <td>0.451706</td>\n",
       "      <td>-0.833707</td>\n",
       "      <td>0.235571</td>\n",
       "      <td>-0.536429</td>\n",
       "      <td>-0.334925</td>\n",
       "      <td>0.608749</td>\n",
       "      <td>...</td>\n",
       "      <td>0.263373</td>\n",
       "      <td>-1.149155</td>\n",
       "      <td>0.817467</td>\n",
       "      <td>-0.411012</td>\n",
       "      <td>0.168704</td>\n",
       "      <td>-1.578113</td>\n",
       "      <td>1.022128</td>\n",
       "      <td>-0.373967</td>\n",
       "      <td>-1.026395</td>\n",
       "      <td>0.214134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train_1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.269958</td>\n",
       "      <td>-0.622136</td>\n",
       "      <td>1.190357</td>\n",
       "      <td>-0.688845</td>\n",
       "      <td>0.790973</td>\n",
       "      <td>1.539897</td>\n",
       "      <td>0.244461</td>\n",
       "      <td>-0.003525</td>\n",
       "      <td>...</td>\n",
       "      <td>0.966609</td>\n",
       "      <td>0.093604</td>\n",
       "      <td>0.443622</td>\n",
       "      <td>1.908760</td>\n",
       "      <td>-0.817592</td>\n",
       "      <td>1.522338</td>\n",
       "      <td>1.067651</td>\n",
       "      <td>-0.129399</td>\n",
       "      <td>0.825415</td>\n",
       "      <td>0.505684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train_2</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.681112</td>\n",
       "      <td>-0.276066</td>\n",
       "      <td>0.516987</td>\n",
       "      <td>0.536515</td>\n",
       "      <td>-0.305476</td>\n",
       "      <td>-0.511032</td>\n",
       "      <td>1.769834</td>\n",
       "      <td>-0.564748</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.072093</td>\n",
       "      <td>0.777995</td>\n",
       "      <td>-0.174130</td>\n",
       "      <td>-0.412315</td>\n",
       "      <td>1.151588</td>\n",
       "      <td>2.297364</td>\n",
       "      <td>-1.617902</td>\n",
       "      <td>-0.695139</td>\n",
       "      <td>-0.381448</td>\n",
       "      <td>0.356681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train_3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.125158</td>\n",
       "      <td>-0.129425</td>\n",
       "      <td>-0.667574</td>\n",
       "      <td>0.195354</td>\n",
       "      <td>0.927990</td>\n",
       "      <td>0.410671</td>\n",
       "      <td>0.500632</td>\n",
       "      <td>-0.474200</td>\n",
       "      <td>...</td>\n",
       "      <td>0.270215</td>\n",
       "      <td>-0.891454</td>\n",
       "      <td>-0.818466</td>\n",
       "      <td>-0.478547</td>\n",
       "      <td>1.607865</td>\n",
       "      <td>-0.789515</td>\n",
       "      <td>-0.959017</td>\n",
       "      <td>1.501741</td>\n",
       "      <td>0.697116</td>\n",
       "      <td>-0.543500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train_4</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.277303</td>\n",
       "      <td>0.035610</td>\n",
       "      <td>0.817681</td>\n",
       "      <td>-0.077829</td>\n",
       "      <td>0.738605</td>\n",
       "      <td>0.955572</td>\n",
       "      <td>0.613370</td>\n",
       "      <td>0.791542</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.036189</td>\n",
       "      <td>0.688986</td>\n",
       "      <td>-1.405984</td>\n",
       "      <td>1.468532</td>\n",
       "      <td>-1.501098</td>\n",
       "      <td>-0.958471</td>\n",
       "      <td>0.297626</td>\n",
       "      <td>0.645536</td>\n",
       "      <td>0.706316</td>\n",
       "      <td>-0.525374</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 202 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID_code  target     var_0     var_1     var_2     var_3     var_4  \\\n",
       "0  train_0       0 -0.577100 -1.273734  0.451706 -0.833707  0.235571   \n",
       "1  train_1       0  0.269958 -0.622136  1.190357 -0.688845  0.790973   \n",
       "2  train_2       0 -0.681112 -0.276066  0.516987  0.536515 -0.305476   \n",
       "3  train_3       0  0.125158 -0.129425 -0.667574  0.195354  0.927990   \n",
       "4  train_4       0 -0.277303  0.035610  0.817681 -0.077829  0.738605   \n",
       "\n",
       "      var_5     var_6     var_7    ...      var_190   var_191   var_192  \\\n",
       "0 -0.536429 -0.334925  0.608749    ...     0.263373 -1.149155  0.817467   \n",
       "1  1.539897  0.244461 -0.003525    ...     0.966609  0.093604  0.443622   \n",
       "2 -0.511032  1.769834 -0.564748    ...    -0.072093  0.777995 -0.174130   \n",
       "3  0.410671  0.500632 -0.474200    ...     0.270215 -0.891454 -0.818466   \n",
       "4  0.955572  0.613370  0.791542    ...    -1.036189  0.688986 -1.405984   \n",
       "\n",
       "    var_193   var_194   var_195   var_196   var_197   var_198   var_199  \n",
       "0 -0.411012  0.168704 -1.578113  1.022128 -0.373967 -1.026395  0.214134  \n",
       "1  1.908760 -0.817592  1.522338  1.067651 -0.129399  0.825415  0.505684  \n",
       "2 -0.412315  1.151588  2.297364 -1.617902 -0.695139 -0.381448  0.356681  \n",
       "3 -0.478547  1.607865 -0.789515 -0.959017  1.501741  0.697116 -0.543500  \n",
       "4  1.468532 -1.501098 -0.958471  0.297626  0.645536  0.706316 -0.525374  \n",
       "\n",
       "[5 rows x 202 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.04222029, -0.09318556,  0.03304654, ..., -0.0273592 ,\n",
       "        -0.07509043,  0.01566593],\n",
       "       [ 0.01812239, -0.04176426,  0.07990922, ..., -0.00868663,\n",
       "         0.05541048,  0.03394679],\n",
       "       [-0.05366426, -0.021751  ,  0.040733  , ..., -0.05476944,\n",
       "        -0.03005402,  0.02810258],\n",
       "       ...,\n",
       "       [ 0.01325155, -0.06269251, -0.00568559, ..., -0.01550069,\n",
       "        -0.05018594,  0.05346474],\n",
       "       [-0.02109078, -0.11453175,  0.07283222, ...,  0.08116989,\n",
       "        -0.00754205, -0.06729738],\n",
       "       [ 0.0049826 , -0.07779551,  0.04100039, ..., -0.0604931 ,\n",
       "        -0.09591487,  0.02561756]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "features = [c for c in train.columns if c not in ['ID_code', 'target']]\n",
    "\n",
    "#X_test = test[features].values\n",
    "#X = train.drop(['target','ID_code'], axis=1)\n",
    "#y = np.array(train['target'])\n",
    "\n",
    "\n",
    "#   \n",
    "#normalized_X = preprocessing.normalize([x_array])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {\n",
    "    'bagging_freq': 5,\n",
    "    'bagging_fraction': 0.335,\n",
    "    'boost_from_average':'false',\n",
    "    'boost': 'gbdt',\n",
    "    'feature_fraction': 0.041,\n",
    "    'learning_rate': 0.0083,\n",
    "    'max_depth': -1,\n",
    "    'metric':'auc',\n",
    "    'min_data_in_leaf': 80,\n",
    "    'min_sum_hessian_in_leaf': 10.0,\n",
    "    'num_leaves': 13,\n",
    "    'num_threads': 8,\n",
    "    'tree_learner': 'serial',\n",
    "    'objective': 'binary',\n",
    "    'verbosity': 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_folds = 2\n",
    "target = train['target']\n",
    "features = [c for c in train.columns if c not in ['ID_code', 'target']]\n",
    "normalizer = preprocessing.Normalizer().fit(train[features])  # fit does nothing\n",
    "normalizer\n",
    "normalizer.transform(train[features])  \n",
    "\n",
    "folds = KFold(n_splits=num_folds, random_state=2319)\n",
    "oof = np.zeros(len(train))\n",
    "getVal = np.zeros(len(train))\n",
    "predictions = np.zeros(len(target))\n",
    "feature_importance_df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Light GBM Model\n",
      "Fold:1\n",
      "Training until validation scores don't improve for 4000 rounds.\n",
      "[5000]\ttraining's auc: 0.921814\tvalid_1's auc: 0.894835\n",
      "[10000]\ttraining's auc: 0.935552\tvalid_1's auc: 0.89705\n",
      "Early stopping, best iteration is:\n",
      "[9499]\ttraining's auc: 0.934328\tvalid_1's auc: 0.897143\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-e317c576d82a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     25\u001b[0m     \u001b[0mfeature_importance_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfeature_importance_df\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfold_importance_df\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m     \u001b[0mpredictions\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_iteration\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_iteration\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mfolds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_splits\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"CV score: {:<8.5f}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mroc_auc_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moof\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'test' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "print('Light GBM Model')\n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds.split(train.values, target.values)):\n",
    "    \n",
    "    X_train, y_train = train.iloc[trn_idx][features], target.iloc[trn_idx]\n",
    "    X_valid, y_valid = train.iloc[val_idx][features], target.iloc[val_idx]\n",
    "    \n",
    "    X_tr, y_tr = augment(X_train.values, y_train.values)\n",
    "    X_tr = pd.DataFrame(X_tr)\n",
    "    \n",
    "    print(\"Fold:{}\".format(fold_ + 1))\n",
    "    trn_data = lgb.Dataset(X_tr, label=y_tr)\n",
    "    val_data = lgb.Dataset(X_valid, label=y_valid)\n",
    "    val_data = lgb.Dataset(train.iloc[val_idx][features], label=target.iloc[val_idx])\n",
    "    \n",
    "    clf = lgb.train(param, trn_data, 1000000, valid_sets = [trn_data, val_data], verbose_eval=5000, early_stopping_rounds = 4000)\n",
    "    oof[val_idx] = clf.predict(train.iloc[val_idx][features], num_iteration=clf.best_iteration)\n",
    "    getVal[val_idx]+= clf.predict(train.iloc[val_idx][features], num_iteration=clf.best_iteration) / folds.n_splits\n",
    "    \n",
    "    fold_importance_df = pd.DataFrame()\n",
    "    fold_importance_df[\"feature\"] = features\n",
    "    fold_importance_df[\"importance\"] = clf.feature_importance()\n",
    "    fold_importance_df[\"fold\"] = fold_ + 1\n",
    "    feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV score: 0.59805 \n"
     ]
    }
   ],
   "source": [
    "test = pd.read_csv(\"test.csv\")\n",
    "normalizer.transform(test[features])  \n",
    "predictions += clf.predict(test[features], num_iteration=clf.best_iteration) / folds.n_splits\n",
    "\n",
    "print(\"CV score: {:<8.5f}\".format(roc_auc_score(target, oof)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "Pred2=pd.DataFrame(predictions)\n",
    "Pred2['target'] = np.mean(Pred2[[col for col in Pred2.columns if col not in ['ID_code', 'target']]].values, axis=1)\n",
    "sub = pd.DataFrame({\"ID_code\": test.ID_code.values})\n",
    "#sub[\"target\"] = predictions['target']\n",
    "#sub.to_csv('submission_PE.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's it. It's now up to you to tune your preprocessing, your algo, and your analysis !\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "name": "Predicting target in train"
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
