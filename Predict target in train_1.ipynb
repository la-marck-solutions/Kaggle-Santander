{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting target in train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sélection des librairies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn as sk\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "from sklearn import preprocessing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importation des bases de données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>var_0</th>\n",
       "      <th>var_1</th>\n",
       "      <th>var_2</th>\n",
       "      <th>var_3</th>\n",
       "      <th>var_4</th>\n",
       "      <th>var_5</th>\n",
       "      <th>var_6</th>\n",
       "      <th>var_7</th>\n",
       "      <th>var_8</th>\n",
       "      <th>...</th>\n",
       "      <th>var_190</th>\n",
       "      <th>var_191</th>\n",
       "      <th>var_192</th>\n",
       "      <th>var_193</th>\n",
       "      <th>var_194</th>\n",
       "      <th>var_195</th>\n",
       "      <th>var_196</th>\n",
       "      <th>var_197</th>\n",
       "      <th>var_198</th>\n",
       "      <th>var_199</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.100490</td>\n",
       "      <td>10.679914</td>\n",
       "      <td>-1.627622</td>\n",
       "      <td>10.715192</td>\n",
       "      <td>6.796529</td>\n",
       "      <td>11.078333</td>\n",
       "      <td>-5.065317</td>\n",
       "      <td>5.408949</td>\n",
       "      <td>16.545850</td>\n",
       "      <td>0.284162</td>\n",
       "      <td>...</td>\n",
       "      <td>3.234440</td>\n",
       "      <td>7.438408</td>\n",
       "      <td>1.927839</td>\n",
       "      <td>3.331774</td>\n",
       "      <td>17.993784</td>\n",
       "      <td>-0.142088</td>\n",
       "      <td>2.303335</td>\n",
       "      <td>8.908158</td>\n",
       "      <td>15.870720</td>\n",
       "      <td>-3.326537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.300653</td>\n",
       "      <td>3.040051</td>\n",
       "      <td>4.050044</td>\n",
       "      <td>2.640894</td>\n",
       "      <td>2.043319</td>\n",
       "      <td>1.623150</td>\n",
       "      <td>7.863267</td>\n",
       "      <td>0.866607</td>\n",
       "      <td>3.418076</td>\n",
       "      <td>3.332634</td>\n",
       "      <td>...</td>\n",
       "      <td>4.559922</td>\n",
       "      <td>3.023272</td>\n",
       "      <td>1.478423</td>\n",
       "      <td>3.992030</td>\n",
       "      <td>3.135162</td>\n",
       "      <td>1.429372</td>\n",
       "      <td>5.454369</td>\n",
       "      <td>0.921625</td>\n",
       "      <td>3.010945</td>\n",
       "      <td>10.438015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.408400</td>\n",
       "      <td>-15.043400</td>\n",
       "      <td>2.117100</td>\n",
       "      <td>-0.040200</td>\n",
       "      <td>5.074800</td>\n",
       "      <td>-32.562600</td>\n",
       "      <td>2.347300</td>\n",
       "      <td>5.349700</td>\n",
       "      <td>-10.505500</td>\n",
       "      <td>...</td>\n",
       "      <td>-14.093300</td>\n",
       "      <td>-2.691700</td>\n",
       "      <td>-3.814500</td>\n",
       "      <td>-11.783400</td>\n",
       "      <td>8.694400</td>\n",
       "      <td>-5.261000</td>\n",
       "      <td>-14.209600</td>\n",
       "      <td>5.960600</td>\n",
       "      <td>6.299300</td>\n",
       "      <td>-38.852800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.453850</td>\n",
       "      <td>-4.740025</td>\n",
       "      <td>8.722475</td>\n",
       "      <td>5.254075</td>\n",
       "      <td>9.883175</td>\n",
       "      <td>-11.200350</td>\n",
       "      <td>4.767700</td>\n",
       "      <td>13.943800</td>\n",
       "      <td>-2.317800</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.058825</td>\n",
       "      <td>5.157400</td>\n",
       "      <td>0.889775</td>\n",
       "      <td>0.584600</td>\n",
       "      <td>15.629800</td>\n",
       "      <td>-1.170700</td>\n",
       "      <td>-1.946925</td>\n",
       "      <td>8.252800</td>\n",
       "      <td>13.829700</td>\n",
       "      <td>-11.208475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.524750</td>\n",
       "      <td>-1.608050</td>\n",
       "      <td>10.580000</td>\n",
       "      <td>6.825000</td>\n",
       "      <td>11.108250</td>\n",
       "      <td>-4.833150</td>\n",
       "      <td>5.385100</td>\n",
       "      <td>16.456800</td>\n",
       "      <td>0.393700</td>\n",
       "      <td>...</td>\n",
       "      <td>3.203600</td>\n",
       "      <td>7.347750</td>\n",
       "      <td>1.901300</td>\n",
       "      <td>3.396350</td>\n",
       "      <td>17.957950</td>\n",
       "      <td>-0.172700</td>\n",
       "      <td>2.408900</td>\n",
       "      <td>8.888200</td>\n",
       "      <td>15.934050</td>\n",
       "      <td>-2.819550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.758200</td>\n",
       "      <td>1.358625</td>\n",
       "      <td>12.516700</td>\n",
       "      <td>8.324100</td>\n",
       "      <td>12.261125</td>\n",
       "      <td>0.924800</td>\n",
       "      <td>6.003000</td>\n",
       "      <td>19.102900</td>\n",
       "      <td>2.937900</td>\n",
       "      <td>...</td>\n",
       "      <td>6.406200</td>\n",
       "      <td>9.512525</td>\n",
       "      <td>2.949500</td>\n",
       "      <td>6.205800</td>\n",
       "      <td>20.396525</td>\n",
       "      <td>0.829600</td>\n",
       "      <td>6.556725</td>\n",
       "      <td>9.593300</td>\n",
       "      <td>18.064725</td>\n",
       "      <td>4.836800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>20.315000</td>\n",
       "      <td>10.376800</td>\n",
       "      <td>19.353000</td>\n",
       "      <td>13.188300</td>\n",
       "      <td>16.671400</td>\n",
       "      <td>17.251600</td>\n",
       "      <td>8.447700</td>\n",
       "      <td>27.691800</td>\n",
       "      <td>10.151300</td>\n",
       "      <td>...</td>\n",
       "      <td>18.440900</td>\n",
       "      <td>16.716500</td>\n",
       "      <td>8.402400</td>\n",
       "      <td>18.281800</td>\n",
       "      <td>27.928800</td>\n",
       "      <td>4.272900</td>\n",
       "      <td>18.321500</td>\n",
       "      <td>12.000400</td>\n",
       "      <td>26.079100</td>\n",
       "      <td>28.500700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 201 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              target          var_0          var_1          var_2  \\\n",
       "count  200000.000000  200000.000000  200000.000000  200000.000000   \n",
       "mean        0.100490      10.679914      -1.627622      10.715192   \n",
       "std         0.300653       3.040051       4.050044       2.640894   \n",
       "min         0.000000       0.408400     -15.043400       2.117100   \n",
       "25%         0.000000       8.453850      -4.740025       8.722475   \n",
       "50%         0.000000      10.524750      -1.608050      10.580000   \n",
       "75%         0.000000      12.758200       1.358625      12.516700   \n",
       "max         1.000000      20.315000      10.376800      19.353000   \n",
       "\n",
       "               var_3          var_4          var_5          var_6  \\\n",
       "count  200000.000000  200000.000000  200000.000000  200000.000000   \n",
       "mean        6.796529      11.078333      -5.065317       5.408949   \n",
       "std         2.043319       1.623150       7.863267       0.866607   \n",
       "min        -0.040200       5.074800     -32.562600       2.347300   \n",
       "25%         5.254075       9.883175     -11.200350       4.767700   \n",
       "50%         6.825000      11.108250      -4.833150       5.385100   \n",
       "75%         8.324100      12.261125       0.924800       6.003000   \n",
       "max        13.188300      16.671400      17.251600       8.447700   \n",
       "\n",
       "               var_7          var_8      ...              var_190  \\\n",
       "count  200000.000000  200000.000000      ...        200000.000000   \n",
       "mean       16.545850       0.284162      ...             3.234440   \n",
       "std         3.418076       3.332634      ...             4.559922   \n",
       "min         5.349700     -10.505500      ...           -14.093300   \n",
       "25%        13.943800      -2.317800      ...            -0.058825   \n",
       "50%        16.456800       0.393700      ...             3.203600   \n",
       "75%        19.102900       2.937900      ...             6.406200   \n",
       "max        27.691800      10.151300      ...            18.440900   \n",
       "\n",
       "             var_191        var_192        var_193        var_194  \\\n",
       "count  200000.000000  200000.000000  200000.000000  200000.000000   \n",
       "mean        7.438408       1.927839       3.331774      17.993784   \n",
       "std         3.023272       1.478423       3.992030       3.135162   \n",
       "min        -2.691700      -3.814500     -11.783400       8.694400   \n",
       "25%         5.157400       0.889775       0.584600      15.629800   \n",
       "50%         7.347750       1.901300       3.396350      17.957950   \n",
       "75%         9.512525       2.949500       6.205800      20.396525   \n",
       "max        16.716500       8.402400      18.281800      27.928800   \n",
       "\n",
       "             var_195        var_196        var_197        var_198  \\\n",
       "count  200000.000000  200000.000000  200000.000000  200000.000000   \n",
       "mean       -0.142088       2.303335       8.908158      15.870720   \n",
       "std         1.429372       5.454369       0.921625       3.010945   \n",
       "min        -5.261000     -14.209600       5.960600       6.299300   \n",
       "25%        -1.170700      -1.946925       8.252800      13.829700   \n",
       "50%        -0.172700       2.408900       8.888200      15.934050   \n",
       "75%         0.829600       6.556725       9.593300      18.064725   \n",
       "max         4.272900      18.321500      12.000400      26.079100   \n",
       "\n",
       "             var_199  \n",
       "count  200000.000000  \n",
       "mean       -3.326537  \n",
       "std        10.438015  \n",
       "min       -38.852800  \n",
       "25%       -11.208475  \n",
       "50%        -2.819550  \n",
       "75%         4.836800  \n",
       "max        28.500700  \n",
       "\n",
       "[8 rows x 201 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We apply the preparation that you defined. You should not modify this.\n",
    "\n",
    "train = pd.read_csv(\"train.csv\")\n",
    "test = pd.read_csv(\"test.csv\")\n",
    "\n",
    "train.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fonction d'augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment(x,y,t=2):\n",
    "    xs,xn = [],[]\n",
    "    for i in range(t):\n",
    "        mask = y>0\n",
    "        x1 = x[mask].copy()\n",
    "        ids = np.arange(x1.shape[0])\n",
    "        for c in range(x1.shape[1]):\n",
    "            np.random.shuffle(ids)\n",
    "            x1[:,c] = x1[ids][:,c]\n",
    "        xs.append(x1)\n",
    "\n",
    "    for i in range(t//2):\n",
    "        mask = y==0\n",
    "        x1 = x[mask].copy()\n",
    "        ids = np.arange(x1.shape[0])\n",
    "        for c in range(x1.shape[1]):\n",
    "            np.random.shuffle(ids)\n",
    "            x1[:,c] = x1[ids][:,c]\n",
    "        xn.append(x1)\n",
    "\n",
    "    xs = np.vstack(xs)\n",
    "    xn = np.vstack(xn)\n",
    "    ys = np.ones(xs.shape[0])\n",
    "    yn = np.zeros(xn.shape[0])\n",
    "    x = np.vstack([x,xs,xn])\n",
    "    y = np.concatenate([y,ys,yn])\n",
    "    return x,y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalisation des données "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = train['target']\n",
    "features = [c for c in train.columns if c not in ['ID_code', 'target']]\n",
    "normalizer = preprocessing.Normalizer().fit(train[features])\n",
    "normalizer\n",
    "normalizer.transform(train[features]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {\n",
    "    'bagging_freq': 5,\n",
    "    'bagging_fraction': 0.335,\n",
    "    'boost_from_average':'false',\n",
    "    'boost': 'gbdt',\n",
    "    'feature_fraction': 0.041,\n",
    "    'learning_rate': 0.0083,\n",
    "    'max_depth': -1,\n",
    "    'metric':'auc',\n",
    "    'min_data_in_leaf': 80,\n",
    "    'min_sum_hessian_in_leaf': 10.0,\n",
    "    'num_leaves': 13,\n",
    "    'num_threads': 8,\n",
    "    'tree_learner': 'serial',\n",
    "    'objective': 'binary',\n",
    "    'verbosity': 1}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modélisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_folds = 5\n",
    " \n",
    "\n",
    "folds = KFold(n_splits=num_folds, random_state=2319)\n",
    "oof = np.zeros(len(train))\n",
    "getVal = np.zeros(len(train))\n",
    "predictions = np.zeros(len(target))\n",
    "feature_importance_df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Light GBM Model\n",
      "Fold:1\n",
      "Training until validation scores don't improve for 4000 rounds.\n",
      "[5000]\ttraining's auc: 0.913502\tvalid_1's auc: 0.895626\n",
      "[10000]\ttraining's auc: 0.924081\tvalid_1's auc: 0.89891\n",
      "[15000]\ttraining's auc: 0.932378\tvalid_1's auc: 0.899237\n",
      "Early stopping, best iteration is:\n",
      "[13778]\ttraining's auc: 0.930457\tvalid_1's auc: 0.899279\n",
      "Fold:2\n",
      "Training until validation scores don't improve for 4000 rounds.\n",
      "[5000]\ttraining's auc: 0.914423\tvalid_1's auc: 0.894878\n",
      "[10000]\ttraining's auc: 0.924895\tvalid_1's auc: 0.898014\n",
      "[15000]\ttraining's auc: 0.933077\tvalid_1's auc: 0.898194\n",
      "Early stopping, best iteration is:\n",
      "[12177]\ttraining's auc: 0.928571\tvalid_1's auc: 0.898379\n",
      "Fold:3\n",
      "Training until validation scores don't improve for 4000 rounds.\n",
      "[5000]\ttraining's auc: 0.913654\tvalid_1's auc: 0.899161\n",
      "[10000]\ttraining's auc: 0.924178\tvalid_1's auc: 0.901699\n",
      "[15000]\ttraining's auc: 0.932417\tvalid_1's auc: 0.901632\n",
      "Early stopping, best iteration is:\n",
      "[12089]\ttraining's auc: 0.927785\tvalid_1's auc: 0.90181\n",
      "Fold:4\n",
      "Training until validation scores don't improve for 4000 rounds.\n",
      "[5000]\ttraining's auc: 0.914716\tvalid_1's auc: 0.897787\n",
      "[10000]\ttraining's auc: 0.925197\tvalid_1's auc: 0.90077\n",
      "[15000]\ttraining's auc: 0.933384\tvalid_1's auc: 0.900862\n",
      "Early stopping, best iteration is:\n",
      "[13033]\ttraining's auc: 0.930288\tvalid_1's auc: 0.900982\n",
      "Fold:5\n",
      "Training until validation scores don't improve for 4000 rounds.\n",
      "[5000]\ttraining's auc: 0.913255\tvalid_1's auc: 0.901002\n",
      "[10000]\ttraining's auc: 0.923883\tvalid_1's auc: 0.90376\n",
      "[15000]\ttraining's auc: 0.93223\tvalid_1's auc: 0.903953\n",
      "Early stopping, best iteration is:\n",
      "[12312]\ttraining's auc: 0.927841\tvalid_1's auc: 0.904025\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "print('Light GBM Model')\n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds.split(train.values, target.values)):\n",
    "    \n",
    "    X_train, y_train = train.iloc[trn_idx][features], target.iloc[trn_idx]\n",
    "    X_valid, y_valid = train.iloc[val_idx][features], target.iloc[val_idx]\n",
    "    \n",
    "    X_tr, y_tr = augment(X_train.values, y_train.values)\n",
    "    X_tr = pd.DataFrame(X_tr)\n",
    "    \n",
    "    print(\"Fold:{}\".format(fold_ + 1))\n",
    "    trn_data = lgb.Dataset(X_tr, label=y_tr)\n",
    "    val_data = lgb.Dataset(X_valid, label=y_valid)\n",
    "    val_data = lgb.Dataset(train.iloc[val_idx][features], label=target.iloc[val_idx])\n",
    "    \n",
    "    clf = lgb.train(param, trn_data, 1000000, valid_sets = [trn_data, val_data], verbose_eval=5000, early_stopping_rounds = 4000)\n",
    "    oof[val_idx] = clf.predict(train.iloc[val_idx][features], num_iteration=clf.best_iteration)\n",
    "    getVal[val_idx]+= clf.predict(train.iloc[val_idx][features], num_iteration=clf.best_iteration) / folds.n_splits\n",
    "    \n",
    "    fold_importance_df = pd.DataFrame()\n",
    "    fold_importance_df[\"feature\"] = features\n",
    "    fold_importance_df[\"importance\"] = clf.feature_importance()\n",
    "    fold_importance_df[\"fold\"] = fold_ + 1\n",
    "    feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV score: 0.90083 \n"
     ]
    }
   ],
   "source": [
    "test = pd.read_csv(\"test.csv\")\n",
    "normalizer.transform(test[features])  \n",
    "predictions += clf.predict(test[features], num_iteration=clf.best_iteration) / folds.n_splits\n",
    "\n",
    "print(\"CV score: {:<8.5f}\".format(roc_auc_score(target, oof)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "Pred2=pd.DataFrame(predictions)\n",
    "Pred2['target'] = np.mean(Pred2[[col for col in Pred2.columns if col not in ['ID_code', 'target']]].values, axis=1)\n",
    "sub = pd.DataFrame({\"ID_code\": test.ID_code.values})\n",
    "\n",
    "sub[\"target\"] = Pred2['target']\n",
    "sub.to_csv('submission_PE.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>test_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>test_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>test_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>test_3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>test_4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>test_5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>test_6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>test_7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>test_8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>test_9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>test_10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>test_11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>test_12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>test_13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>test_14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>test_15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>test_16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>test_17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>test_18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>test_19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>test_20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>test_21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>test_22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>test_23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>test_24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>test_25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>test_26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>test_27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>test_28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>test_29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199970</th>\n",
       "      <td>test_199970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199971</th>\n",
       "      <td>test_199971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199972</th>\n",
       "      <td>test_199972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199973</th>\n",
       "      <td>test_199973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199974</th>\n",
       "      <td>test_199974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199975</th>\n",
       "      <td>test_199975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199976</th>\n",
       "      <td>test_199976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199977</th>\n",
       "      <td>test_199977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199978</th>\n",
       "      <td>test_199978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199979</th>\n",
       "      <td>test_199979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199980</th>\n",
       "      <td>test_199980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199981</th>\n",
       "      <td>test_199981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199982</th>\n",
       "      <td>test_199982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199983</th>\n",
       "      <td>test_199983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199984</th>\n",
       "      <td>test_199984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199985</th>\n",
       "      <td>test_199985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199986</th>\n",
       "      <td>test_199986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199987</th>\n",
       "      <td>test_199987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199988</th>\n",
       "      <td>test_199988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199989</th>\n",
       "      <td>test_199989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199990</th>\n",
       "      <td>test_199990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199991</th>\n",
       "      <td>test_199991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199992</th>\n",
       "      <td>test_199992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199993</th>\n",
       "      <td>test_199993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199994</th>\n",
       "      <td>test_199994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199995</th>\n",
       "      <td>test_199995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199996</th>\n",
       "      <td>test_199996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199997</th>\n",
       "      <td>test_199997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199998</th>\n",
       "      <td>test_199998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199999</th>\n",
       "      <td>test_199999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200000 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            ID_code\n",
       "0            test_0\n",
       "1            test_1\n",
       "2            test_2\n",
       "3            test_3\n",
       "4            test_4\n",
       "5            test_5\n",
       "6            test_6\n",
       "7            test_7\n",
       "8            test_8\n",
       "9            test_9\n",
       "10          test_10\n",
       "11          test_11\n",
       "12          test_12\n",
       "13          test_13\n",
       "14          test_14\n",
       "15          test_15\n",
       "16          test_16\n",
       "17          test_17\n",
       "18          test_18\n",
       "19          test_19\n",
       "20          test_20\n",
       "21          test_21\n",
       "22          test_22\n",
       "23          test_23\n",
       "24          test_24\n",
       "25          test_25\n",
       "26          test_26\n",
       "27          test_27\n",
       "28          test_28\n",
       "29          test_29\n",
       "...             ...\n",
       "199970  test_199970\n",
       "199971  test_199971\n",
       "199972  test_199972\n",
       "199973  test_199973\n",
       "199974  test_199974\n",
       "199975  test_199975\n",
       "199976  test_199976\n",
       "199977  test_199977\n",
       "199978  test_199978\n",
       "199979  test_199979\n",
       "199980  test_199980\n",
       "199981  test_199981\n",
       "199982  test_199982\n",
       "199983  test_199983\n",
       "199984  test_199984\n",
       "199985  test_199985\n",
       "199986  test_199986\n",
       "199987  test_199987\n",
       "199988  test_199988\n",
       "199989  test_199989\n",
       "199990  test_199990\n",
       "199991  test_199991\n",
       "199992  test_199992\n",
       "199993  test_199993\n",
       "199994  test_199994\n",
       "199995  test_199995\n",
       "199996  test_199996\n",
       "199997  test_199997\n",
       "199998  test_199998\n",
       "199999  test_199999\n",
       "\n",
       "[200000 rows x 1 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's it. It's now up to you to tune your preprocessing, your algo, and your analysis !\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "name": "Predicting target in train"
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
